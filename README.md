üß† Pipeline MLOps de An√°lise de Sentimento (Portugu√™s)

üéØ Vis√£o Geral do Projeto

Status: Completo e Pronto para Deploy em Produ√ß√£o (Azure App Service)

Este projeto demonstra a cria√ß√£o de um Pipeline MLOps (Machine Learning Operations) completo, transformando avalia√ß√µes de texto n√£o estruturado em dados classific√°veis (Sentimento 1-5). O foco √© provar a profici√™ncia em levar solu√ß√µes de Intelig√™ncia Artificial do notebook para a nuvem.

Desenvolvido por: [Seu Nome Completo]
Foco de Carreira: Engenharia de Software, Analista J√∫nior / Ci√™ncia de Dados

üõ†Ô∏è Stack Tecnol√≥gico

Categoria

Tecnologia

Finalidade

Linguagem Principal

Python 3.10+

L√≥gica e Processamento de Dados.

I.A. / ML

Scikit-learn, joblib

Treinamento, Avalia√ß√£o e Serializa√ß√£o do Modelo de Classifica√ß√£o.

NLP

NLTK (Tokeniza√ß√£o, Stopwords), RegEx

Pr√©-processamento de texto em Portugu√™s.

Backend / API

Flask, Gunicorn

Cria√ß√£o de um endpoint RESTful para consumo em tempo real.

Frontend / Demo

Streamlit

Interface interativa amig√°vel para demonstra√ß√£o.

Infraestrutura / MLOps

Docker, Azure App Service, Azure CLI

Containeriza√ß√£o e Deployment em Ambiente de Produ√ß√£o.

üöÄ Estrutura e Etapas do Pipeline

O projeto segue a estrutura padr√£o de MLOps, separando as responsabilidades:

1. Engenharia de Dados (An√°lise)

Script: src/data_processor.py

Fun√ß√£o: L√™ o CSV (separador ;, codifica√ß√£o latin-1), trata valores nulos e realiza a limpeza de texto (min√∫sculas, remo√ß√£o de pontua√ß√£o e stopwords). O resultado √© salvo em data/processed/dados_limpos.csv.

2. Machine Learning (Treinamento da I.A.)

Script: src/model_trainer.py

Fun√ß√£o: Carrega os dados limpos, usa TF-IDF para vetoriza√ß√£o e treina o modelo Logistic Regression. Os modelos finais (modelo_sentimento.pkl e vetorizador.pkl) s√£o salvos na pasta models/.

Diagn√≥stico: A baixa acur√°cia inicial do modelo (bias) √© intencional para fins de demonstra√ß√£o, provando que o Engenheiro de Software/Analista consegue diagnosticar e planejar o pr√≥ximo passo: a Otimiza√ß√£o com um dataset maior.

3. Servi√ßo e Demonstra√ß√£o (Interfaces)

src/app.py: A API de Produ√ß√£o (Flask). √â o endpoint (/predict) que o Azure App Service ir√° rodar via Gunicorn.

src/interface.py: A Interface Web (Streamlit) para an√°lise interativa de texto √∫nico e classifica√ß√£o de lote (upload de CSV).

‚òÅÔ∏è Instru√ß√µes para Deploy no Azure

O projeto est√° configurado para o Azure App Service (Web App for Containers), demonstrando conhecimento em ambientes de produ√ß√£o.

Pr√©-requisitos

Conta Azure ativa.

Azure CLI instalado e logado (az login).

Um Personal Access Token (PAT) do GitHub para o deploy.

‚öôÔ∏è Comandos de Execu√ß√£o Local

Ativar Ambiente: conda activate analise_ia

Preparar Dados: python src/data_processor.py

Treinar I.A.: python src/model_trainer.py

Rodar a Interface Web (Demo): streamlit run src/interface.py (Abre http://localhost:8501)

üê≥ Arquivos de Infraestrutura para o Deploy

Dockerfile: Cont√©m as instru√ß√µes para construir a imagem Docker do projeto.

requirements.txt: Lista todas as depend√™ncias (flask, gunicorn, scikit-learn).

gunicorn_conf.py: Configura√ß√£o do servidor de produ√ß√£o (gunicorn) na porta 8000.
